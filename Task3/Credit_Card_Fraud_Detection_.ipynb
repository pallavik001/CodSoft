{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "WZya_8WaPxKv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "credit_df = pd.read_csv(\"creditcard.csv\")\n",
        "credit_df.head(10)"
      ],
      "metadata": {
        "id": "as2WKGb5P0Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical description of the dataset\n",
        "description_stats = credit_df.describe()"
      ],
      "metadata": {
        "id": "oQ9HikVwP0tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = credit_df.isnull().sum()"
      ],
      "metadata": {
        "id": "bqj1Ih_OP2Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate normal and fraud transactions\n",
        "normal_df = credit_df[credit_df.Class == 0]\n",
        "fraud_df = credit_df[credit_df.Class == 1]\n",
        "print(\"Normal Transactions Shape:\", normal_df.shape)"
      ],
      "metadata": {
        "id": "3XYE6fieP3WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical summary of transaction amounts for normal transactions\n",
        "normal_amount_stats = normal_df.Amount.describe()\n",
        "print(\"Normal Transactions Amount Stats:\\n\", normal_amount_stats)"
      ],
      "metadata": {
        "id": "mHed1Xr0QDqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical summary of transaction amounts for fraud transactions\n",
        "fraud_amount_stats = fraud_df.Amount.describe()\n",
        "print(\"Fraud Transactions Amount Stats:\\n\", fraud_amount_stats)"
      ],
      "metadata": {
        "id": "wiy9s29BQEZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by class and calculate the mean for each feature\n",
        "class_means = credit_df.groupby('Class').mean()\n",
        "print(\"Class Means:\\n\", class_means)"
      ],
      "metadata": {
        "id": "WNFA8sydQF2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample normal transactions to match the number of fraud transactions\n",
        "sampled_normal_df = normal_df.sample(n=492)"
      ],
      "metadata": {
        "id": "ElObL9MEQHk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine sampled normal transactions with fraud transactions\n",
        "combined_df = pd.concat([sampled_normal_df, fraud_df], axis=0)"
      ],
      "metadata": {
        "id": "B0Eq4fJYQJzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of instances for each class in the combined dataset\n",
        "combined_class_counts = combined_df['Class'].value_counts()\n",
        "print(\"Combined Class Counts:\\n\", combined_class_counts)"
      ],
      "metadata": {
        "id": "hKWcgG-zQPvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by class and calculate the mean for each feature in the combined dataset\n",
        "combined_class_means = combined_df.groupby('Class').mean()\n",
        "print(\"Combined Class Means:\\n\", combined_class_means)"
      ],
      "metadata": {
        "id": "ppLvvMiAQRE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features (X) and target variable (Y)\n",
        "X_combined = combined_df.drop(columns='Class', axis=1)\n",
        "Y_combined = combined_df['Class']"
      ],
      "metadata": {
        "id": "YIHegoCYQSjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the combined dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_combined, Y_combined, test_size=0.2, stratify=Y_combined, random_state=2)\n"
      ],
      "metadata": {
        "id": "ujjU-QWwQU78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the logistic regression model\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "id": "wZPi4ZJlQWx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on training set\n",
        "Y_train_pred = logistic_model.predict(X_train)\n",
        "training_accuracy = accuracy_score(Y_train_pred, Y_train) * 100\n",
        "print(f\"Training Accuracy: {training_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "mw5EWqHfQXV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on test set\n",
        "Y_test_pred = logistic_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(Y_test_pred, Y_test) * 100\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "7-AYES6bQZLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}